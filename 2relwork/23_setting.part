\section{Study Setting: Oceanography}

In this section, I transition to describing the setting of this study: oceanography, and more specifically, code work as it interacts with other ways of knowing in this multi-disciplinary field.  In the previous section, I included various discussion of code practice and products. Talking about these concepts in the abstract may under-emphasize just how much the pursuit of science is driven by awe, and the extent to which oceanographers often see software work as arguably the least riveting component of their work, but also an amazing opportunity to build new forms of knowledge. For some, it is at times the least enjoyable, though there are many who derive joy from the particular attentive problem-solving of code work. In this, as in many respects, oceanographers form a diverse and excited crowd. The goal of this section is to provide examples and grounding of what ``doing oceanography,'' practically, involves, and what motivates those who do it.


\begin{figure}
    \centering
    \linespread{1.0}
    \resizebox{1\textwidth}{!}{\input{2relwork/PlaceofCode.tex}}
    \caption[Places of code work in oceanography.]{\textbf{The place of code work in oceanography.} Loci for code work include: \textbf{(A)} data processing tightly coupled to collection method (e.g., with code work \cite{davis1996rapid} and without code work \cite{yamamoto1986small}); \textbf{(B)} data presentation and stewardship; \textbf{(C)} existing modeling practice (see \textit{A Vast Machine} on the history of modeling \cite{edwards2010vast}, and Section 2.1 for recent studies on software practice in the modeling context, notably the Heaton and Carver review \cite{heaton2015claims}); \textbf{(D)} an opportunity for innovation for better comparisons. In this diagram, I distinguish observational and modeling oceanography (described in Section 2.2). Additionally, the dashed border to denote `optional' code work indicates code work loci with particularly wide ranges of automation, from end-user programming (with Excel or LabVIEW), to scripting (with R or Python), to engineering a custom analytic pipeline. See also \ref{fig:ch7toc} for a breakdown of where computer science can intervene on the basis of collaboration loci, which complements this more domain-science-focused illustration.}
    \label{fig:poc}
\end{figure}


\subsection{Identities of an Oceanographer}

In an excellent history of oceanography, focusing on the last century to the present, \emph{Mapping The Deep}, Robert Kunzig offers the following description of a British researcher who was instrumental in developing the field's understanding of deep ocean currents (emphasis added):

\litquote[pp. 283-286]{kunzig2000mapping}{John Swallow was \textbf{an oceanographer's oceanographer}: a man with a pure love of studying the sea. ... [He recalled of his experiences being drafted into the Royal Navy in WWII:] ``I found I was quite happy going to sea and crawling around a ship mending electronic equipment.'' ... Swallow was a soft-spoken man, modest about his own insights into questions of great import ... a man who was quite happy not to be working on anything ``important;' at all; a man who liked quiet and liked tinkering with instruments - and who had a great gift for making them work at sea.)}

Swallow was a physical oceanographer in the late 1950s who sought to collect data to measure deep-ocean currents. This predated satellite navigation, so his floats were constructed to emit sounds that could be picked up by hydrophones within a few miles. Multiple such measurements allowed him to find the position relative to the ship, while the ship itself could fix its own absolute position using a nearby anchored buoy. These observations confirmed theories of intense currents on the ocean floor, capable of transporting nutrients and organisms globally. Later, he decided to release clusters of floats, at depths up to 13k feet (almost 4k meters), and return to locate them every few days or a week. He assumed they would be moving no more than half a mile a day, and as a whole they would show an overall northward flow. However, he was surprised to discover that they were moving much faster (up to half a mile an hour). Furthermore, they did not move consistently northward as expected, but in a surprising variety of direction. This was the discovery of ``mesoscale'' eddies, ``long-lasting but not permanent, with diameters of roughly 10 to 100 miles ... the physical analogue of local weather systems in the atmosphere,'' but in the ocean \cite{kunzig2000mapping}!

This story from the late-1950s chapter of oceanography research illustrates (1) the ocean is mysterious and even the fundamentals, like the overall movement of the water, are profoundly difficult to measure, thereby requiring (2) invention and discovery within the discipline that spans theory, hardware, and collective data efforts. For such historical contexts, I include excerpts from Kunzig's \emph{Mapping the Deep}, as well as from Edward's \emph{A Vast Machine} \cite{edwards2010vast}. These are excellent books on, respectively, the recent history of oceanography in general and the history and politics of climate modeling.

What oceanographers consider legitimate activities in their field varied widely. Although all study participants were in a university department encompassing  ocean science, none would self-identify to their peers as an ``oceanographer'' without further explanation. Furthermore, certaintly none would claim the kind of confidence ascribed to Swallow in the above excerpt. In the rest of section, my aim is to provide enough detail in which to ground the various self-identifications, and the resulting motivations and work environments, that provide the vital backdrop for the upcoming discussion of code work in the next chapters. This background for code work in oceanography is illustrated using participant quotes.

\subsection{General and Specific Scientific Work}
Over lunch, Erin and Lindsay, two post-doctoral fellows,\footnote{In the RegionalNowcast-Model team, as introduced in Chapter 3.} explain to me that earth and ocean sciences encourage a degree of generalization, where people are familiar with every step of the research process from the murky deep to the lab to the spreadsheet. In their case, researchers are expected to be familiar with steps from mathematical representations to numerical approximation methods for solving systems of differential equations to the website with the visualizations. Despite an expectation of competence and understanding at every step, oceanographers do not tend to self-identify as general-purpose oceanographers with no other modifiers attached.

A post-doctoral researcher,\footnote{In the CustomInstrument-Lab team, as introduced in Chapter 3.} Mallory, tells me that there are two kinds of people in oceanography: methods-oriented people and question-oriented people. She explains that it is easier, and ``more efficient,'' to be the former, though she identifies more with the latter group. A researcher can have a method and apply it to different questions - sitting in her chair, she points at the imaginary questions surrounding her; she is the essence of the method, sitting in the center of its observable universe. In this way, she tells me that people get known for their methods: ``oh that's the [method/approach for analysis] guy, he'll do [very specific kind of] analysis for you.'' The alternative is asking a set of questions from various angles: she interlaces her fingers, and forms an oblique mysterious object at which she, the researcher, peers it from different sides. She identifies as the latter kind, which she sees as relatively more rare, having transitioned from modeling and physical oceanography to observational work and working with environmental data focused more on questions of biology. Even in physical oceanography, she had worked on incorporating biology into the model, so the subject of study has persisted through the transition.


%Mallory and Ryan, a graduate student in one of the groups, both see themselves as transitioning between being focused on models and being focused on data. Ryan went from working with environmental data to working with models, whereas Mallory did the opposite. Their experiences put them in a position of articulating these divides. The differences between different parts of oceanography are, to begin with, important to understanding oceanography because they are how oceanographers self-identify.

%"I am not a real programmer" is the self-deprecating statement among the three most common things that people told me, however, it was never uttered with any apparent expression of wanting to become a "real programmer." 
%Another reason that these distinctions matter is that they are each associated with a different environment, or "stack," if we return to the "full-stack" terminology borrowed from software engineering with which I began this section. For example, Erin in Group D was explaining to me choosing to write a python script duplicating the functionality of an existing toolset - as she explained and as I kept asking questions, it became apparent that the reason for her choice lay not only in an assessment of what is necessary, but also in associating a different working environment with her distinct "data" and "model" modes.

\subsection{Computational Models}

Throughout this manuscript, a \emph{model} refers a piece of software that uses numerical approximation approaches to solve systems of differential equations. Depending on the context of the conversation, the \emph{system of differential equations} itself can be referred to as ``the model,'' as can the programmatic \emph{implementation} of some numerical approximation for solving the equations, or a specific \emph{instantiation} (parameterization) of the code (as in, in comparing results of different runs). The equations describe \emph{change} - the movement of particles or tracers from place to place, or their transformation over time. Tracers refer to relevant measurable data, like salinity and temperature.

The domains of interest are bounded by both the surrounding land topography and underwater topography. The latter may be referred to as \textit{bathymetry}, which is the study of underwater topography. For example, the depth included in an analysis or a visualization can come from one of several possible `bathymetry files.' Sometimes `the bathymetry' may be described as not quite accurate relative to the real world, but preferable because using it produces more realisti results in the model. These lines that separate water from not-water in the world of modeling are precise, but mediated by the complexity of the model and the state of the best understanding of  the world. The parameters and the relationships between measurable elements are also precise within the model, but related to reality by a series of decision made by a group of people or - often - a single individual tacking a specific question. Veronica, a graduate student\footnote{In the RegionalNowcast-Model group, as introduced in Chapter 3.} comments on a model that their group (along with many other groups) use, which has a dizzying multitude of parameters. All the while, she tells me people are working on new packages; during the course of this project, the group had undergone a somewhat involved process of updating the code to an upgraded version with some substantial changes\footnote{intended to make it more usable but actually inspiring the ire of ``software advisor'' of the RegionalNowcast-Model group; this role, and ``The Upgrade'' story, are both introduced in Chapter 3.}. People write packages, Veronica tells me, because ``if someone wants to see internal waves, they need a different mixing parameterization,'' and the model is big and popular enough that there are dedicated developers to make sure everything is compatible.

Models represent ``different worlds;'' the things that happen in models ``are real,'' they just may or may not match the observed world in one or more measurable ways.  The processes of explicit and implicit comparison to observed reality, and the state of the art of understanding reality, guide the decisions of which instantiation of a model is \emph{better}. The model output, therefore, \emph{is never interpreted in isolation} but only in its relationship to other comparable phenomena. Comparability is, therefore, both central and a major challenge, which I will return to again and again throughout the dissertation.
%The act of comparison through visual inspection is considered treatment in the section on visual practice (Chapter TK). The act of \emph{inducing comparability through sufficiently-convincing transformation} is considered in the section on code work, particularly the parts on representation work (Chapter TK). Debugging at various stages of the model is discussed in Chapter TK.

The practice of modeling hinges on comparability. However, comparability is relatively difficult to achieve because of differences between models and even bigger differences between models and observations. Models are different in their spatial domain and the time range they span, as well as the space and time resolution. A model that covers a lot of ground and a lot of time and very high resolution can be prohibitive in its demand of computational resources; these models are shared by oceanographers and it can be difficult to get time to run experiments. Modeling more constrained domains at lower resolutions can be accomplished on individual researchers' laptops in a reasonable time span for experiments and iterations.

What kind of model something is depends on which first-order mechanisms it includes. The atmosphere is the wind at the surface; it is possible to ``add the atmosphere to the model,'' which means including an equation that describes the relationship between the wind and the measurable variables at the surface. Alternatively, one can choose to ``leave out the atmosphere'' or to use ``atmospheric forcings,'' which means including the influence of atmospheric variables - like the wind - with constants that affect the ocean but without modeling the variable itself. The model is complex. The ``physics'' of the model describe how movement is handled, but the mechanism may vary in detail, complexity, and realism. What ``kind'' of a model something is may depend also on the focus of study.

For example, a biogeochemical model is used to study something like $CO_2$, or a bio model to investigate phytoplankton growth. The focus dictates what first order mechanisms are necessary to include (such as nutrient availability and grazers at at top and bottom). Because a simpler model is a better model - both conceptually and computationally - those mechanisms that do not affect the phenomenon of interest would be left out. Elements like nutrients can be considered chemicals, but an oceanographer wouldn't call it a biogeochemical model unless she has more of a focus on the chemistry, like particle dynamics. Because of this, when a modeler is working on doing something to a model, she may describe her work as ``adding biology,'' and go on to explain the particular first-order mechanisms, in the form of variables and equations, that she is adding.

\subsection{The Beauty of Box Models}

Underneath the software implementation and the numerical approximation lies the conceptual articulation of dynamical processes, or the box model.  Each box in a box model represents a distinct segment of the ocean that behaves differently: the segment for the surface, the segment for the deep; the segment for the tropics and the segment for the sub-tropics. The boxes are made by partitioning the original box horizontally or vertically, adding arrows with transitions, represented by equations. Nina, a junior graduate student\footnote{In the BioGeoChem-Model team, as introduced in Chapter 3.}, explained box models to me with palpable enthusiasm. She tells me that this is important for understanding the first-order mechanisms, which she cannot do with the large general circulation models (GCMs). Though initially skeptical, in practice she found that, indeed, those are too complicated, hard to understand. She tells me that GCM output studies need a section on validating with a box model, except for some of the huge IPCC ones. ``If [my office-mate] was here, he would sing many praises to the box model.''

Nina herself had only been exposed to the idea for a year, but she described them ``amazing, like magic, didn't believe them at first.'' The box model is elevated relative to the programming aspect of modeling: ``The coding is the easy part. Well, sorta easy, but you can do it in a day. Then you interpret it, and that's why you can write a paper on it.'' She first explains that, generally, you ought to use no more than 3 or 4 boxes and that gives you a lot of complexity and power already, but in the same breath she tells me about her ``favorite box model paper'' which ``goes \textit{all the way} up to 7 boxes!'' The paper she shows is remarkable in particular in its high level of complexity, and the strength of its argument for why this complexity is necessary. Box models are ways to computationally and conceptually divide the ocean into a few elegant segments in order to focus on effects of particular dynamics.
 
%[OCNA\_FN150702\_KK]

\subsection{Fieldwork and Interconnectedness}

The primary subjects of study are conceptually interconnected. Additionally, the two modes of work (fieldwork-oriented and model-oriented) are procedurally interconnected. Models use observations to verify, observations are triangulated with other observations. In both cases, oceanographers proceed with caution and use as much of the available knowledge as possible to inform how the collection of environmental data is targeted, or how the model is parameterized. The key power of models is the capacity of the researcher to ``take out'' or ``add'' the first-order mechanisms; in this way, engaging with models offers the power to make causal claims. Though conceptually and procedurally interconnected, there are distinct values and practices associated with each.

%\tk More on this interdependence and how is makes it challenging to use observations: ``Reanalysis offers something that traditional climate data will never achieve: physically consistent data across all climate variables. Traditional climate data are `single variable': you get a set of averages for temperature, another one for pressure, a third for precipitation, a  fourth for sunshine, and so on. Each type of observation is independent of the others, but in the real atmosphere these quantities are interdependent. Reanalysis models simulate that interdependence, permitting a large degree of cross-correction, and they generate all variables for every gridpoint.'' \cite{edwards2010vast}

%Distinguishing communities and roles is not just a theoretical act, however."A classification of work becomes a political actor in the attempts to establish power on broad institutional levels" (STO). One of the goals of the
%Moore/Sloan Data Science Environments Initiative, for example, is to make
%explicit the contribution of the data scientists to domain scientific teams.
%This is intended to allow for establishing data science career paths, and for
%rewarding following best practices. which on the one hand aims to give credit
%where credit is due, and on the other reinforce institutional boundaries that,
%in the case of specific groups or individuals, are much less
%straightforward. (STO)


Time is of crucial importance on board a ship not (only) because of a general preference for faster algorithms\footnote{which is an intrinsically important feature of any algorithm in computer science, where the goal is not only to make some current task possible, but to make it so trivial that whole scores of other tasks become possible as well.} but because observations in a cruise context happen on a schedule and are mindful of the water budget. A variety of instruments (floats that follow the ship, or a rosette lower form the ship) are used to collect readings and/or water samples from various depths at particular stations. In this paper, the authors mention damming; one of the teams\footnote{The CustomInstrument-Lab team, as introduced in Chapter 3.} has an instrument that filters water as it passes through. Water samples can be filtered and/or kept in a fridge for analysis after the cruise. CTD (conductivity - which is directly related to salinity - temperature and depth) sensors are attached to the metal frame of the rosette, and the floats. At one point, as I was getting a tour of an oceanography building on campus, some technicians were outfitting a float in a break-out area. They explained that other sensors may be attached as well, relative to the needs of the research team in question.

%\kt{have not introduced team yet}
On another occasion, during a brown-bag lunch with members an ocean-going group in the study, they explain to me that if they have data coming in from their instrument, it's up to whichever member on the team is on board to write impromptu scripts in any language of choice to aid decisions on tuning the instrument \emph{in medias res}. A senior post-doc, George, tells me with excitement and pride of a recent cruise where the findings from the on-board analysis of their data provided valuable information for everyone on board, and was useful in choosing the route and timing of the cruise. It is not uncommon for decisions to be made in the course of a cruise that change the plan, though there is a detailed plan beforehand; to aid this, there is a Chief Scientist who balances pragmatic constraints and overlapping or conflicting scientific needs.

% TODO - transition is largely missing

\subsection{Time and Seasonality}

Time plays a crucial role in both the content and conduct of research, whether it is observational or modeling. In the observational case, time constrains the sample analysis and filtering that can take place; especially if the research cruise has a schedule of visiting different stations, and if the researchers are interested in comparing their measurement across different points in the day-night cycle (the ``diel'' or ``diurnal'' cycle refers to movement of certain organisms vertically, for example), in which case comparability between different days requires collection at roughly similar times during the day. %This has to do with rates of, for example, photosynthesis, which are dependent on sunshine; or tides; even when the relationship is not so obvious, there are marked changes in the environment between day and night that the daily cycle is represented in presentations of time-series data at the scale of days.

Many of the datasets and their associated displays extend  over multiple months or multiple years. In this case, it is the cycling of seasons that introduces variation to be taken into account. Depending on the research question, it may be meaningful to compare years only by way of comparing the same season across years. Observational and model data alike can be plotted on these scales, sometimes together for comparison. The challenge of observational and model comparisons at finer-resolution time-scales, and of comparing between observations, is that if the measurement is interesting to look as it varies through the day, it begins to matter exactly how the different data sources are \emph{normalized}. And when it comes to comparisons on coarser-grained but longer, even geological timescales, or forecasting into the future, observational data scarcity becomes a challenge.

%\kt{jumped w shift to modeling - gina}
In addition to ways in which time impacts the construction of oceanographic data as well as its representation, there are also familiar organizational seasons and rhythms: the addition of new group members, mentorship and teaching built into academic responsibilities alongside research, publication and grant-writing cycles. When it comes to the observation of code work, it is subordinate to all of these constraints. The maintenance of code in science can  be seen as ``extra'' work (borrowing the term from Trainer et al. \cite{trainer2015personal}), secondary to the other ``scientific'' (unlike code, despite its pervasive important \cite{paine2014producing}) duties. For example, the decision to use one programming language over another has, in the groups that have the most direct collaboration on code among members\footnote{CustomInstrument-Lab and the RegionalNowcast-Model}, been driven at least as much by technical considerations as reasoning about the hypothetical future students, or hypothetical future constraints of the senior researchers in managing their tasks. 

% In short, photographs of fish and similar visual objects are not generally material to the \emph{visual narratives} across the projects included.


\subsection{Images and Communication}

When the participants present talks to one another, for feedback or to share findings, there are photographs of the cruise and its crew, perhaps of the trawl net or the water-filtering instrument or rosette involved. Organisms are represented with beautifully-rendered images of diatoms. There are images of the area studied, which are colored in pixelated-looking shades of the rainbow, denoting the grid-size and providing an overview of the result, if they are produced by modeling.%There is a passage in \emph{A Vast Machine} on maps in oceanography \cite{edwards2010vast}: TK %TODO

The images of the area studied may also be satellite shots of a particular region, with squiggly line (or lines) marking the path of research cruises. Imagine slicing the 3D water-mass using the squiggly cruise-path line as a guide. A \emph{transect} chart shows a a contour of the ocean floor along the x-axis and depth on the -axis (with 0 at the top). The ocean floor is not visible from the satellite, and individual cruises do not usually chart the shape of the bottom as part for the course.

\subsection{Ways of Knowing}

The \emph{bathymetry} file that provides this data is one of the many instances of ubiquitous data re-use and triangulation of information from a variety of stakeholders and institutions in the field, as an interviewee\footnote{From a set of interviews conducted with oceanographers, among others, by members of Charlotte P. Lee's group in spring of 2014.} explains at one point: ``Rivers have to come from a variety of sources, primarily U.S. Geological Survey. And then tides, that's easy. And then bathymetry comes from a hodgepodge of sources, often a NOAA database.'' % [OCNX_INT140421]
As a computer scientist, my impulse is to accept that someone somewhere create sufficiently-reliable bathymetry understanding, and that if I were to use that, the provenance is best abstracted out. However, this kind of abstraction also removes the role of disciplinary differences in the ways of knowing, which are increasingly important when the knowledge in question is very difficult to build from limited data sources:

\litquote[p.39]{kunzig2000mapping}{At the turn of the century [1900s], it was still possible to believe, and many geologists did, that Earth was shrinking as it lost its primordial heat; that, as it contracted, clocks of crust subsided to become ocean basins, while others were squeezed upward to form mountain ranges and whole continents; and that low points became high and high became low as the cooling continued and the erosive forces of wind and rain did their steady work on the land. On the other hand, it was also possible to believe, as the \emph{Challenger}'s scientists had come to believe, that the present ocean basis were permanent features of Earth's surface. And finally, it was possible to believe, as a German meteorologist and visionary named Alfred Wegener believed, that continents drifted horizontally across the face of the Earth, ploughing through the ocean basins - which Wegener claimed were basically flat and featureless - as ships plough through water.} %(\cite{kunzig2000mapping} p.39) %p. 31 - determination of depth, sounding, and `obstacles were twofold'

Steinhardt and Jackson describe oceanography as a ``radically unstandardized field ... that has struggled to converge on method and technique above the level of the individual site or PI research program'' \cite{steinhardt2015anticipation}. What became apparent in my observations is that the lack of standardization corresponds to a multi-disciplinary methodological pluralism. For example, the PI of one of the groups in the study\footnote{The Omics-Lab group, which is introduced formally in the following chapter.} comments in a meeting, as she encourages a student to approach another researcher outside the group for advice on methods: ``this is [the other researcher's] life's work, to make these databases [of sequences], and she's right here! ... I don't know how willing [the other researcher] is to work with our instrument, but if you have data in the right format, it shouldn't matter. She has a lot of experience and opinions about databases, and so do I,'' which she follows up by enumerating some of these differences of opinion. In each of the statements selected and highlighted here, the PI is (in order, corresponding to the statements/sentences): (1) seeking the assistance of an ``owner'' of a method, recognizing the other researcher as the relevant expert; (2) articulating the availability/accessibility in terms of physical or email proximity; (3) delineates the end of an unshareable method (the instrument which the other researcher may not `want' to work with) and the beginning of the shareable method (well-formatted data); and (4) neutrally recognizes the plurality of approaches.

Different ways of knowing inform the content of the claims an narratives made by different kinds of oceanographers. In the anecdote with which I opened this chapter, excerpted from \textit{Mapping the Deep}, Kunzig attaches the theories to people, and points out their backgrounds (geologist; scientists previously introduced with the Challenger crew; meteorologist). Talking with Mallory, she mentions that she came to two researchers at UW with a question, and it ``left me sort of reeling: interesting conversations but unclear how to proceed. They gave essentially completely opposite answers,'' depending on the scale at which they commented. Previously, she had pointed out that the scale of physical modeling (often, using 1 by 1 degree grids) is far too coarse to effectively include biology, because biology changes over smaller geographic ranges. Her questions persisted: how far to generalize? How to make sense of patterns in nature?  %Her issue is "how far to generalize” and “make sense of patterns in nature"

Continuing his story about bathymetry, Kunzig notes that ``it was possible to believe many things about the ocean in the early years of the century, because so few things were known. In 1904 ... the newly formed [bureau] had prepared the first standardized bathymetric chart of the world ocean, collecting all the available soundings. There were 18,400 of them. That was not enough to understand the ocean floor, and in fact geologists did not begin to understand the overall architecture of the ocean floor - or the planet as a whole - until half a century later. Until then, they really did not know what they were talking about.'' However, knowing that ``you do not know what you are talking about'' requires the wisdom of hindsight. In the moment, all a scientist has at their disposal is their varied skills, their research intuition and taste, and their vigilant skepticism and striving for control and transparency whenever possible.