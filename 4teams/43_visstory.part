\section{Visualization and Storytelling}

Code that works settles into shared libraries or infrastructure and becomes invisible, apparent only at points of breakdown or through contingency planning \cite{star1999ethnography}. The code is also visible during the constructive phase. At the moment that a piece of written code is executed, it becomes a kind of autonomous agent. All code observed in this study, spanning scripts, models, and analysis pipelines, was intended to be understandable, but took iterative improvements to get there. During that time, the ``agency'' of code consisted of those actions which lay beyond the vision of the programmer by virtue of unexpected side-effects or bugs. In an analysis of 200,000 bug report titles, Ko et al. report that ``95\% of noun phrases referred to visible software entities, physical devices, or user actions'' \cite{ko2006linguistic}. Even functional and at some level understandable, some code (e.g., complex Intergovernmental Panel on Climate Change (IPCC) general circulation models (GCMs)) can be oblique enough to demand the treatment of itself as an agent, such as when as the researcher ``figures out what the code is doing.''

All code acts on the world according to its own principles, which are intended to be understood by the researcher, but in practice diverge in inevitably surprising ways in the  actual implementation. As such an agent, it inspires hope, scrutiny, playfulness, and fear. In reference to discovery and exploration of available tools and processes, the phrase ``playing around with [e.g., a new tool or programming language]'' is at least as common as ``learning about [same].'' In describing a problem, a scientist may say that a program ``does not like'' particular values or actions. In other words, the program is buggy, but the ``animating'' narration imbues code with the capacity to petulantly reject a request. In particular back-up choices, the coding scientist may reveal fear of irreparable damage - by changing the code or by unleashing some big automated operation onto some precious data. The code may or may not ``work,'' and the scientist concerns herself with ways to ``convince'' herself that it works. When it \emph{does} work, the program has the capacity, by virtue of speed and complexity of the actions it can carry out relative to a human, to awe and delight.

When code manages to inspire joy (or even relief, as opposed to frustration), it does so through the charts and figures that is it able to produce or facilitate. Visualization is not only ubiquitous, but elicits so much interaction that it serves as a primary way for an observer (me) to be able to witness participants reflect on their work practices. While bringing me up to speed on her work following a conference, Mallory jokes that ``[we are] professional skeptics in science, and sometimes [it is frustrating; and you want to say:] `just \emph{shush}, I'm just showing a figure!''' Throughout the study, it became apparent that most of the time, there no such thing as ``\emph{just} a figure,'' confirming Mallory's quip about professional skepticism toward every figure. Visualizations are central to the scientific practice observed; they are routinely used to interrogate the analysis process in the course of an individual doing trouble-shooting, as well as in a collaborative feedback setting. If a visual display of data or information is shown, on a computer screen or the projector, it remains there for at least a few minutes as those present consider it and ask questions and offer their ideas.%\footnote{See also the story in 5.1 Data Representation on the frustration of the computer scientist who attempts to make a figure to demonstrate a computation process, but is met with resistance because she has not used the correct parts of the complex dataset: ``this is a database, we can filter that out later! I was \emph{just} plotting something!''}


How do these visual objects support narration and interrogation of research process?
Storytelling using visual artifacts ``animates'' the salient objects - oceanic (``the little guys''), chemical/physical (``the particles''), or technological (``the function'') - as primary actors in stories, imbued with actions, desires, and preferences. For example, ``this function \textit{wants} this type of thing for input, and it \textit{doesn't like} for the input to have such-and-such properties.'' Animating these inanimate objects focuses scrutiny on that object during trouble-shooting that traces the provenance of data as is is carried from the water, through data collection hardware or filtering protocol, converted into lossy numerical representations, and then transformed to match other data as part of triangulating some conceptualization. Code written to facilitate these transformations must be transparent, understandable,  and convincing. When a study participant says, ``I am just tyring to convince myself that it works,'' she is applying the same level of scrutiny as she would imagine a colleague would in a collaborative session or during peer review. If an interactive chart is not persuasive in a manuscript, then its utility in the course of analysis is diminished relative to a chart that could be used to build an argument to scientific peers.


%When watching a talk by an unfamiliar oceanographer, to figure out what kind of oceanography is being presented is helps to listen for the phrase ``the little guys'' in reference to something under investigation; ``the little guys'' may be phytoplankton, diatoms, bacteria, or clumps of organic matter forming particles. In the case of eddies and other physical - rather than biological or chemical - subjects of study, there may not be an explicit mention of ``the little guys'' but there will almost certainly be a  tendency to speak declarative, active-voice sentences, with the inanimate oceanic phenomenon (like an eddy) as the subject of movement, transport, and other exciting activities. An easy way to figure out whether the speaker is focused on observational or model data is by whether or not there were photos of the ship and/or its crew, and a map marked with the trajectory (or trajectories) of the cruises or the locations of the floats or other unmanned environmental data collection means.

Narration of physical, chemical, or biological processes is built up from first principles, taking into account the connections between different resolutions, and ultimately is intended to  ``make sense'' in an intuitive way to the trained ear. For example, if a hypothesis involves adding a lot of freshwater to the ocean, one way for this idea to ``make sense'' is by doing a back-of-the-envelope calculation of how much fresh water that would need to be. If it exceeds by an order of magnitude the effect of the ice caps spontaneously melting, that is just too much for the behavior of the model to apply to our present reality under conceivable conditions.  In telling the history of climate modeling, Edwards in \emph{A Vast Machine} describes ways in which climate and sensor data is created by the instruments: the digitization and instrumentation processes themselves modifying the resulting numbers and how they can be used. This constraint the freedom to interpret on corresponding data provenance is evident throughout the collegial debates observed, but the complexity of the provenance challenge is reduced to the indictment of numbers as ``real,'' ``made up,'' or ``guesses.''

For example, Colleen, a post-doc in the Omics-Lab team, is showing some new visualizations she had just made in Tableau, where she has plotted concentration in \textit{fmoles}. Femtomole (fmol) is $10^{-15}th$ of a mole. It is a unit for measuring the amount of a substance. The question is, ``how much of \textit{this} thing is in \textit{there}?'' The answer might involve counting, if the thing is organisms, and the goal is to study their death or reproduction. The answer might be in grams, if it is a nutrient that is used up. A mole is a counting measure used in chemistry to reason about the quantities of molecules as they react to form other molecules. In the equation $2H_2 + O_2 \rightarrow 2H_2O$, it would be confusing to measure in weight, since the molecular weights are so distinct.  The PI of cuts her off (in a welcome, teaching, but uncompromising manner): ``fmols are not real.'' In her typically somewhat playful and casual tone, Colleen retorts that the units are ``...\textit{sorta} real?'' In this case, the PI does not shift toward neutral pluralism that I have pointed out before\footnote{See the end of Section 3.2.}, but instead explains that the distinction between counting and weight produces ``totally different shapes'' for two outputs that are bout ``about amount,'' even though both are at least ``sorta'' real.

The visual language of this setting helps not only convey the information, but some sense of how this information was produced, at least at a birds-eye view. For example, below I explain discrete marks and color gradients in a few typical variations as immediately signalling something about data provenance, as part of a consistent visual debugging language.

\textbf{Discrete Marks.} Multiple dots can refer either to observations in the environment or to ``different worlds'' produced by a model. Different model runs, parameterized in a different way, are comparable and therefore can exist on the same plot. Marks can be dots, or more complex glyphs such as ellipses, to represent current magnitude and direction in a single, accepted mark. When presented in a spatial plot (with X-Y axes mapping to longitude), the marks refer to measurements in that area, and may be glyphs - using color and shape to encode additional variables. When there are lines as well, the lines correspond to continuous model results (over time or at varying depths) that can be compared to the discrete dots of measurements.

\textbf{Bounded color gradients.} Edges delineate the region of interest by bounding the bottom of the ocean, and the banks separating the shore and the sea. If edges of a particular region are shown, the region of interest is typically also overlayed with colors. Here, the rainbow spectrum might be used, as might the blue-white-red scale. For all the visual benefits of the blue-white-red scale, it prevents the representation of missing data in white. I have seen this scale used either because the researchers (in the BioGeoChem-Model team) were actively trying to move away from the rainbow spectrum as harder to perceive, or (as in the RegionalNowcast-Model team) to denote that the numbers corresponded to a difference between two results being compared (so there is zero, positive and negative).

\textbf{Smoothness} in the image can be a meaningful signal: a ``pixelated'' appearance of a bounded color gradient suggests that this is a model result and the model uses this grid. Conversely, in a depth profile, smoothness suggests model results \emph{or} measurements that were made in sufficiently similar conditions at short intervals and can therefore be represented in a continuous manner.

Transformations are ubiquitous and every transformation is subject to scrutiny via the charts it produces. Visual artifacts therefore have some properties and requirements to enable this scrutiny. They are:

\begin{itemize}
    \item \textit{Pervasive and flexible.} Visualization was the output of every act in the research pipeline. Though pervasive, it took on different roles in different contexts. Flexibility to be modified in order to be comparable with other data forms or sources was a crucial aspect.
    \item \textit{Diagnostic and verbose.} A chart facilitates fast assessment of whether anything stands out, in the sense of looking ``wrong'' or ``off.'' If it passes this diagnostic muster, the next step is to see whether it suggests anything interesting. Simultaneously, the chart is used to verify that individual expectations of behavior are met (e.g., that the surface temperatures ``look right''). The visualization must encode enough information to be an effective tool at different levels of interrogation. Sometimes, this means that its geographic or temporal range is limited.
    \item \textit{Fast and reproducible.} Visualizations are embedded in a process of rapid prototyping and decision-making. For example, ``which boundary conditions best reproduce observed patterns relevant for question or hypotheses?'' Answering this question involves running the model with different boundary conditions, as well as running it for multiple timescales. In modeling, the decisions are about which parametrization, boundary condition, bathymetry, and so on, best reproduces the measures most relevant to the object of study. In observational data, the decision-making process aims to identify the best way to represent the data without mis-representing it. In both cases, rapid iteration allows to minimize spurious features in the visualization.
    \item \textit{Intriguing and Exciting.} A single finished chart gets at least a half a minute of uninterrupted, silent consideration from its audience, be it in a presentation, or looking over the shoulder on the computer screen. It is intended to enable the audience to ask deeper questions that may require similarly-complex follow-up charts. In the case of observing over the shoulder, the follow-up charts may be created on the fly as a living embodiment of an ongoing discussion. As in Subsection 3.3.2, \textit{The Beautiful Chart}, the visual products were the primary means by which a member of one team inspired a member of the other team to voluntarily set aside an entire day \textit{that week} to do a lab task he would have otherwise not done at all, but in this case was quite excited about.
%    \item Comparability and triangulation. 
\end{itemize}

As an observer, I was struck that it seemed like the beginning and end of every discrete research endeavor was a chart: the initial provocation piquing interest;  mid-task diagnostics, where a researcher might ``convince myself that it works;'' the final critique, a beautiful enhancement, or exciting support of a hunch. The chart deserving \textit{wows} is the one which manages to use simplicity to communicate something complex about a phenomenon or process is the ocean. The talks observed in course presentations,  practice talks, and more formal completed presentations were each a collection of charts with commentary, often with a significant chunk of time spent using a wooden or laser pointer to identify regions of interest. \kt{In \textit{Laboratory Life}, Latour and Woolgar claim that the iterative transformation of data into successive inscription devices is associated with increased abstraction \cite{latour2013laboratory}. In \textit{Seeing Like a Rover}, Vertesi stressed the role of the image in scientific work as not only creating an artifact of a scientific process, but the scientific process itself.}

Although many visualizations are only ever seen by one person, all visual artifacts incorporate elements that make them potentially viable in a social context. The ideal end result of a visualization is a complex chart demonstrating how multiple data sources come together to support a coherent causal claim. It is meant, therefore, to persuade a wide audience of inter-disciplinary researchers. But even the most ephemeral visual artifact is a persuasive tool, described as necessary for ``convincing myself'' that the analysis, or some part of it, works and the results are meaningful.

On many occasions, a visual object is produced by an individual to aid communication. The object in question has ``weird'' or ``interesting'' features, and the subject of discussion is resolving these features into a causal explanation. The result of the discussion is either an explanation of how the chart does, in fact, ``make sense,'' or a concrete next step to investigate the ``weird'' feature or to further explore the ``interesting'' one. The level of scrutiny applied to both is similar, though the ``interesting'' receives enthusiasm where the ``weird'' receives a persistent, puzzle-solving sort of dedication. In this context, the key requirement is of the visual artifact to be easy to share. Examples given in Section 4.1 included arranging printed charts, or projecting in a group setting. The core design requirements here are ease, control and reconfigurability.

These interactions can be reminiscent of the aspect of \textit{pair programming } which stresses a distinction between the person ``driving'' the computer, and the person who is engaging but purposely not physically manipulating the keyboard. Leaving the ``driving'' to only one person, in this setting typically the person who is explicitly asking for help from someone with the same level of experience or more, accomplishes two things. First, it reduces the mystery of every step in the transformations or manipulations. The alternative is confusion and a sense of powerlessness. For example, one post-doctoral researcher notes that the ``software advisor'' in the group is very quick to fix the issue but seems annoyed and reluctant to explain, so that it is difficult to fix the same issue later. Driving, in certain contexts, may also reflect a recognition of an ownership of a problem-and-method combination by a particular person. While some questions from the colleagues (or supervisor) of the individual who made the charts can be at the level of guidance and explanation, many are questions to which the answer is only known by that person, who has spent time immersed in their idea. %The transition from targeted teaching to open-ended discussion is audible in the point-of-view of the speaker: the teaching-in-second-person pattern is replaced by a questions that animate the oceanic or the software/analytic agent in the third person.

This dynamic combines open-ended discussion and formal data-intensive analysis in a way that is difficult to support with ``fancy'' visualization software. I saw little ``collaborative visualization'' in the sense of multiple people working on a single visual artifact simultaneously. Mostly, the visual artifact was the product of a complex thought process of a person that was then used to reveal that thought process to their colleagues for the purpose of feedback. More importantly, the comparison and triangulation that is at the core of this exercise can be done either at the level of plotting additional data points for comparison or by articulating a known pattern verbally (e.g., ``we expect to see this kind of salinity at the surface, but not in the deep''). This ``informal'' comparison that draws on shared knowledge - articulated as a hunch or as a whiteboard squiggle - is a crucial step of interpreting and interrogating a new visual data artifact. Remote collaborations that required visualization were sustained via static images and very long emails or video calls. These patterns of sharing were pervasive, creative (spanning a variety of visual elements for condensing and communicating data), and robust (not brittle once the artifacts are created).  %\gn{maybe make the point explicitly about how collaborative viz that is set up for remote collab could stop this kind of pair programming discourse}%In terms of tooling, any visualization environment which encodes too much of the comparison violates this requirement.
%
%\kt{TODO-2 transition}