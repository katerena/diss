\section{Summary of Recommendations}

The purpose of this chapter was to demonstrate the utility of the proposed conceptual framework, particularly with regard to evaluation of interventions. In each of the sections, I describe a case study of a complex situation that involved some adoption/adaptation, but also some rejection of particular intervention components, or their critique. The take-aways for each of the case studies are included below:

\begin{itemize}
    \item When building something integrative or holistic, consider ways that its components can be made available piecewise and engage with the existing skill and enthusiasm in the target-user scientific community.
    \item Focusing on technological deliverables and goals creates pressure; focusing on time spent cultivating community or learning a new vocabulary or way of thinking creates momentum.
    \item Set initial, ambitious goals, against which outcomes will be measured, without unintentionally privileging any one part (technological, social, or cognitive) of the working environment over the others.
\end{itemize}

Taking these suggestions as a whole, the implication of this work for design and practice is to \textbf{articulate goals in ways that can reward community and skill related improvements}, because there is relatively less uncertainty associated with these than with increasingly large or ambitious programming projects. The take-aways are intended to be useful for anyone about to invest time and energy in a project that carries with it an inevitable amount of risk.

In the parts of this sections where I expressly highlight criticism of some software intervention, I hope not to disparage the intervention, but to expose that the vocabulary for criticism of something that is broken is considerably more detailed than that for the opposite. One of WW's indictments about the conduct of the OOI (introduced in Section 7.1) is that ``Rather than publicly acknowledging this failure and co-opting the extensive data management expertise and facilities that already reside within the NSF Geoscience community to solve this problem, the OOI is instead funding [external] engineers working at [another university] to cobble together a system at the last minute in the hopes that nobody will notice that anything has gone wrong'' \cite{wilcockshambles}. It is not the failure of a project under fire here so much as the failure of reflecting and moving past that failure. 

The obvious opposite of criticism of brokenness - ``praise of things which are not broken'' - is neither actionable or timely. Criticism follows a breakdown, but functioning infrastructure is invisible. My intention in this chapter was to highlight other timely opportunities for encouragement and positive feedback. The first recommendation suggests recognizing hacks and workarounds that require manual intervention as not only clever (these usually exploit existing channels in new ways, and therefore \textit{are} quite clever) but also revealing important information about how the ``non-hacky-way of doing things'' might be improved in design. The second recommendation offers a concrete way to cope with uncertainty by creating community momentum (through group work) and opportunity (through time-constrained effort) - and not measuring the outcome beyond this momentum and opportunity as it affects the particular context. The third recommendation stresses the necessity of articulating, in group settings, the learnings and change that \textit{has} occurred in situations where there might be a sense of unsuccessful adoption, or ``going right back to where we started'' for all those affected, despite their different valuations. 

%
In Chapter 5, I outline some of the best practices and claim that what they offer, upon adoption, is not so much a guarantee of success but a \textit{language}. As SWC interviewees, quoted in Chapter 6, state, language and vocabulary are a major learning goal from attending such short-term educational initiatives. All these recommendations attempt to formalize looking on the bright side of possible failure, which ought to be seen as inevitable as projects involve more people, longer time spans, and more ambitious cross-overs between disciplines. Encouraging the sharing of negative results and disappointing data are among the top priorities for discussion of ``best practices'' in open science, and so should be the development of concrete ways to deliver interpersonal rewards in the wake of code work not panning out as well as hoped or intended. 
