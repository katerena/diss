\section{Awareness and Intention}

The high cost - chiefly in terms of attention, but also in time and money - of follow-through on some call to action means that, for the most part, ideas about change remain in decision-making limbo. In the previous section,  I wrote about the \textit{action} step of the \textit{moment of flux}, as illustrated in the Figure \ref{fig:cycle2}. Escalation toward action requires \textit{opportunity and momentum}. In this section, I also review \textit{de-escalation}, and the pre-cursor steps of \textit{awareness} and \textit{intention}. The primary difference between these two ``steps'' is that neither involves actually adoption, but one is much more receptive to suggestions from a trustworthy ``champion'' of a tool or protocol.

\textbf{Awareness} of is amplified and sustained through social channels (``I had heard about git but I haven’t used it''). As a scientist continually evaluates and re-evaluate their current working environment and adapt their course of its intentional and unintentional change to point toward the collective imagination of the perfect world, he may at one point form an \textbf{intention} to make some particular change or learn a particular skill. This intention follows awareness but may remain passive indefinitely (e.g., ``Python has been on my to-do list for a long time'').

Intention can subside down into the maintenance of background awareness, when it is not driven forward by (either external or internal) opportunity and momentum. For example, in one of the post-SWC interviews a participant tells me that she ``went looking for best practices'' but ``life got in the way'' and she needed to do more research design instead of scripting. Ultimately, she used scripts (new knowledge) for selecting sites for data collection, a way in which research design ended up creating an opportunity. However, other higher-priority concerns (professionally or personally) ``getting in the way'' is an example of intention \textit{not} leading to action, but instead retreating back to awareness. %P03

The moment-of-flux relies on not only the momentum and opportunity, but the awareness of possibilities, which is maintained passively over time in the normal course of doing science. For example, Figure \ref{fig:events} in Chapter 3 illustrates different types events observed during this work. These events are arranged by how much close interaction occurs between  the participants/attendees, and how targeted the agenda of the events is to solving a particular problem. Those that are less targeted help to build awareness of the various options, as well as develop the language around  concept. This \textit{awareness-building} is expressed then in statements like, ``I had heard about git but I haven't used it.'' Having this awareness, and seeking out its maintenance relative to a changing landscape of available options, is built in to the range of targeted-ness of group activities undertaken by scientists.%the inclusion criterion as described in the methods section, so I make no claims about its prevalence in the general population of scientists who code.

In my first observation of the RegionalNowcast-Model team, I met Ed, the \textit{software advisor} to the group. Over the course of several months in this study, he went from advising the group in after-hours meetings, to being a formal part-time employee. The first time I met him was at an hour-long meeting from 5 to 6 pm, and after it was over he told me a bit about his background, motivation, and approach. I would summarize a big part of his strategies as strategic omission of unnecessary detail, where he has to make deliberate effort to determine \textit{which} is the detail that is unnecessary in the context: ``you know I just watch them, I can see when their eyes glaze over.'' The relationship he and the PI of the group have had, which was a motivation for him to have gotten engaged in the group prior to having a formal position, also allowed for the kind of feedback that would support this. He tells me, later, that the PI is ``really good at pushing me on it,'' asking him: ``do I [as a scientist] really need to know this?''

The question of how much understanding is needed for a sense of comfort and control depends on the context, and for the most part, the participants in the study wanted more detail, not less, from software. However, even in the above example, the PI did write code in the shared project and run analyses; the ``do I really need to know this?'' was asked as an honest question of what is actually necessary to have a \textit{workable mental model}. One of the informants was recounting having worked with a computing researcher who was specifically aiming to help the group, but it became frustrating: ``I want salt, but he comes back a week later with a machine that not only gives me salt but pepper as well!'' Sometimes the effort to make something ``usable'' seems to invite flexibility, feature creep, and \textit{less} understanding or control over a \textit{more} complex product (Section 7.3 tells a story of one such criticism). The irony in this case was that the function that the researcher wrote was in response to an R question, but there was  already  a simple one-line existing solution, ``but the guy didn't want to take the time to look for it.'' The telling of this story relies on the wisdom of hindsight: the speaker relates this telling after having learned enough R to have found the function.

%A post-doc from the group D also quipped about oceanographers who only analyze data coming out of models, rather than digging in the model code itself: “I would feel nervous in that position [precarious employment.] How can you interpret it if you don’t really know what it’s doing?” The vision of the perfect world with regard to software is neither overwhelming detail nor a black box.% LINK TK

%"* 

%Zach Tatlock:“they don’t want to know the implementation they want a workable mental model" -the scientists want good mental models, neither black boxes nor all the little gory bits of it!

%\kt{TODO continue from here}

%It is entirely possible to do good science, using  R/MATLAB/FORTRAN (among other things) without a working grasp of control structures or code modularity. The resulting coding practice basically did not treat the programming component as distinct from the math it was supposed to embody, aside from something like the numerical approximation method. I sort of hinted at this in mention of the Heaton and Carver talking about design not being a step of programming work \cite{heaton2015claims}; and the mention of the "locus of scrutiny" - which was about what is being debugged when debugging is happening.

%When this happens, the issue is better understood not in terms of "resistance to new languages/environments" but an essentially absent missing mental model for programming and code as something that can be reasoned about outside of the mathematic/scientific context. It's really palpable in software carpentry; mostly when I observed those, I was a "helper," so I worked with students/attendees 1 on 1 to help them through their challenges. And it was quite frustrating for some of them: expecting to "get it," because they have all this programming experience, but not "getting it" because it's a massive mental model shift. So I think that's a more basic education barrier, rather than language inertia.

%There were a couple of instances of this playing out in observing the oceanographers, and there were many more instances (basically, all but the couple of really reluctant/overwhelmed people) of the conceptual barrier not being a problem. This those cases there wasn't really resistance; it pretty much followed the "change" "flow" - find an opportunity (starting a new project or getting unreasonably annoyed); ask a trusted friend/labmate/guy-down-hall/labmate's-significant-other; try something for maybe a day and then decide yes/no. So what people a actually attempted to adopt had more to do with the context of the "trusted individual" gatekeeper, and the extent to which they were able to evaluate the costs, benefits, and available alternatives to come up with a suggestion.

%All such "gatekeepers/quasi-evangelists" who were actually in the study (between 4 and 6, depending on how strict the definition of "gatekeeper" I stick to) described doing work (in terms of estimating costs+benefits, and in articulating concrete ways to explore a particular alternative in a particular work context) in order to avoid pitfalls (and, implicitly, to maintain the level of trust / not waste people's energy).


Few people were still using any of the specific skills they had learned at SWC afterwards. Some had additional motivation embedded in their immediate social context: ``my whole lab uses this, so I have to'' or ``I am a new faculty and I am tarting my own lab, and I want us to use best practices.'' Some had de-escalated from \textit{action} back to \textit{intention}; as I had interviewed people multiple times over the course of several months, I could hear the progression from (1 month from SWC) checking out a book from the library on visualization package in R to (2 months) not quite remembering the book at first when I ask about it to (3 months) just wrapping up with a major task, and looking forward to finally getting into the book. Such disrupted time-lines are not the exception in academic work.
